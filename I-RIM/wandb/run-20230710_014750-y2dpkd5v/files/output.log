68 it number
learning rate: 3.1e-03
num_dense_layers: 1
num_dense_nodes: 82
activation: swish
initialization: Glorot uniform
weight_ic: 1
weight_bcl: 100
weight_bcr: 50
weight_domain: 84
Compiling model...
'compile' took 0.000116 s
Training model...
Step      Train loss                                  Test loss                                   Test metric
0         [7.32e+00, 7.32e-03, 3.35e+01, 8.27e-01]    [7.32e+00, 7.32e-03, 3.35e+01, 8.27e-01]    []
1000      [4.17e-01, 5.61e-02, 1.02e-01, 1.04e-01]    [4.17e-01, 5.61e-02, 1.02e-01, 1.04e-01]    []
2000      [1.39e-01, 1.07e-02, 4.72e-02, 1.73e-02]    [1.39e-01, 1.07e-02, 4.72e-02, 1.73e-02]    []
3000      [7.59e-02, 5.23e-03, 4.41e-02, 1.11e-02]    [7.59e-02, 5.23e-03, 4.41e-02, 1.11e-02]    []
4000      [3.91e-02, 4.80e-03, 3.84e-02, 6.30e-03]    [3.91e-02, 4.80e-03, 3.84e-02, 6.30e-03]    []
5000      [3.60e-02, 3.58e-03, 2.92e-02, 5.88e-03]    [3.60e-02, 3.58e-03, 2.92e-02, 5.88e-03]    []
6000      [3.57e-02, 2.85e-03, 2.29e-02, 5.11e-03]    [3.57e-02, 2.85e-03, 2.29e-02, 5.11e-03]    []
7000      [3.60e-02, 2.17e-02, 2.31e-02, 7.99e-03]    [3.60e-02, 2.17e-02, 2.31e-02, 7.99e-03]    []
8000      [3.49e-02, 2.39e-03, 1.68e-02, 4.92e-03]    [3.49e-02, 2.39e-03, 1.68e-02, 4.92e-03]    []
9000      [3.46e-02, 4.11e-03, 1.50e-02, 5.82e-03]    [3.46e-02, 4.11e-03, 1.50e-02, 5.82e-03]    []
10000     [3.39e-02, 2.60e-03, 1.37e-02, 4.98e-03]    [3.39e-02, 2.60e-03, 1.37e-02, 4.98e-03]    []
11000     [3.33e-02, 2.59e-03, 1.25e-02, 4.63e-03]    [3.33e-02, 2.59e-03, 1.25e-02, 4.63e-03]    []
12000     [3.27e-02, 3.44e-03, 1.62e-02, 5.64e-03]    [3.27e-02, 3.44e-03, 1.62e-02, 5.64e-03]    []
13000     [3.20e-02, 2.92e-03, 1.14e-02, 4.45e-03]    [3.20e-02, 2.92e-03, 1.14e-02, 4.45e-03]    []
14000     [3.08e-02, 3.09e-03, 1.04e-02, 4.45e-03]    [3.08e-02, 3.09e-03, 1.04e-02, 4.45e-03]    []
15000     [2.85e-02, 3.50e-03, 9.52e-03, 4.45e-03]    [2.85e-02, 3.50e-03, 9.52e-03, 4.45e-03]    []
16000     [2.55e-02, 3.76e-03, 8.19e-03, 4.24e-03]    [2.55e-02, 3.76e-03, 8.19e-03, 4.24e-03]    []
17000     [2.22e-02, 3.62e-03, 6.71e-03, 3.99e-03]    [2.22e-02, 3.62e-03, 6.71e-03, 3.99e-03]    []
18000     [1.92e-02, 6.17e-03, 6.19e-03, 4.14e-03]    [1.92e-02, 6.17e-03, 6.19e-03, 4.14e-03]    []
19000     [1.65e-02, 3.34e-03, 4.89e-03, 3.62e-03]    [1.65e-02, 3.34e-03, 4.89e-03, 3.62e-03]    []
20000     [1.48e-02, 2.89e-03, 4.22e-03, 3.32e-03]    [1.48e-02, 2.89e-03, 4.22e-03, 3.32e-03]    []
Best model at step 20000:
  train loss: 2.53e-02
  test loss: 2.53e-02
  test metric: []
Epoch 20000: saving model to /home/giuglielmocappellini/Projects/PINNs/23.07.09_source_m_obs/hpo/129_483/model/68.ckpt-20000.pt ...
'train' took 42.071320 s
Saving loss history to /home/giuglielmocappellini/Projects/PINNs/23.07.09_source_m_obs/hpo/129_483/history/68_loss ...
Saving training data to /home/giuglielmocappellini/Projects/PINNs/23.07.09_source_m_obs/hpo/129_483/history/68_train ...
Saving test data to /home/giuglielmocappellini/Projects/PINNs/23.07.09_source_m_obs/hpo/129_483/history/68_test ...
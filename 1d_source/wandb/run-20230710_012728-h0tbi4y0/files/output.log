49 it number
learning rate: 3.6e-03
num_dense_layers: 1
num_dense_nodes: 125
activation: swish
initialization: Glorot uniform
weight_ic: 13
weight_bcl: 12
weight_bcr: 85
weight_domain: 8
Compiling model...
'compile' took 0.000129 s
Training model...
Step      Train loss                                  Test loss                                   Test metric
0         [9.77e+01, 1.03e-03, 5.53e+01, 8.30e-02]    [9.77e+01, 1.03e-03, 5.53e+01, 8.30e-02]    []
1000      [1.95e-01, 2.43e-01, 9.48e-02, 5.31e-01]    [1.95e-01, 2.43e-01, 9.48e-02, 5.31e-01]    []
2000      [4.79e-02, 1.61e-01, 5.72e-02, 3.70e-01]    [4.79e-02, 1.61e-01, 5.72e-02, 3.70e-01]    []
3000      [5.68e-02, 1.25e-01, 5.28e-02, 2.65e-01]    [5.68e-02, 1.25e-01, 5.28e-02, 2.65e-01]    []
4000      [6.81e-02, 1.15e-01, 4.69e-02, 2.42e-01]    [6.81e-02, 1.15e-01, 4.69e-02, 2.42e-01]    []
5000      [4.81e-02, 2.01e-02, 2.39e-02, 4.30e-02]    [4.81e-02, 2.01e-02, 2.39e-02, 4.30e-02]    []
6000      [3.37e-02, 2.12e-02, 2.38e-02, 3.39e-02]    [3.37e-02, 2.12e-02, 2.38e-02, 3.39e-02]    []
7000      [2.75e-02, 2.01e-02, 2.13e-02, 2.83e-02]    [2.75e-02, 2.01e-02, 2.13e-02, 2.83e-02]    []
8000      [2.42e-02, 1.74e-02, 1.54e-02, 2.15e-02]    [2.42e-02, 1.74e-02, 1.54e-02, 2.15e-02]    []
9000      [2.37e-02, 1.39e-02, 1.26e-02, 1.56e-02]    [2.37e-02, 1.39e-02, 1.26e-02, 1.56e-02]    []
10000     [2.17e-02, 9.87e-03, 9.60e-03, 1.18e-02]    [2.17e-02, 9.87e-03, 9.60e-03, 1.18e-02]    []
11000     [2.12e-02, 8.14e-03, 8.72e-03, 9.97e-03]    [2.12e-02, 8.14e-03, 8.72e-03, 9.97e-03]    []
12000     [2.07e-02, 6.93e-03, 8.26e-03, 8.78e-03]    [2.07e-02, 6.93e-03, 8.26e-03, 8.78e-03]    []
13000     [1.98e-02, 6.29e-03, 7.81e-03, 8.00e-03]    [1.98e-02, 6.29e-03, 7.81e-03, 8.00e-03]    []
14000     [1.85e-02, 6.03e-03, 7.48e-03, 7.18e-03]    [1.85e-02, 6.03e-03, 7.48e-03, 7.18e-03]    []
15000     [1.74e-02, 5.77e-03, 7.24e-03, 6.41e-03]    [1.74e-02, 5.77e-03, 7.24e-03, 6.41e-03]    []
16000     [1.64e-02, 5.58e-03, 7.04e-03, 5.72e-03]    [1.64e-02, 5.58e-03, 7.04e-03, 5.72e-03]    []
17000     [1.59e-02, 5.34e-03, 7.65e-03, 5.33e-03]    [1.59e-02, 5.34e-03, 7.65e-03, 5.33e-03]    []
18000     [1.49e-02, 5.06e-03, 6.72e-03, 4.72e-03]    [1.49e-02, 5.06e-03, 6.72e-03, 4.72e-03]    []
19000     [1.39e-02, 4.86e-03, 6.16e-03, 4.12e-03]    [1.39e-02, 4.86e-03, 6.16e-03, 4.12e-03]    []
20000     [1.34e-02, 4.57e-03, 5.86e-03, 3.80e-03]    [1.34e-02, 4.57e-03, 5.86e-03, 3.80e-03]    []
Best model at step 20000:
  train loss: 2.77e-02
  test loss: 2.77e-02
  test metric: []
Epoch 20000: saving model to /home/giuglielmocappellini/Projects/PINNs/23.07.09_source_m_obs/hpo/129_483/model/49.ckpt-20000.pt ...
'train' took 42.935785 s
Saving loss history to /home/giuglielmocappellini/Projects/PINNs/23.07.09_source_m_obs/hpo/129_483/history/49_loss ...
Saving training data to /home/giuglielmocappellini/Projects/PINNs/23.07.09_source_m_obs/hpo/129_483/history/49_train ...
Saving test data to /home/giuglielmocappellini/Projects/PINNs/23.07.09_source_m_obs/hpo/129_483/history/49_test ...
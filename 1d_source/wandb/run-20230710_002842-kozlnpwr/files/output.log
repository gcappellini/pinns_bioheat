3 it number
learning rate: 3.9e-04
num_dense_layers: 2
num_dense_nodes: 68
activation: selu
initialization: Glorot uniform
weight_ic: 57
weight_bcl: 81
weight_bcr: 87
weight_domain: 50
Compiling model...
'compile' took 0.000120 s
Training model...
Step      Train loss                                  Test loss                                   Test metric
0         [4.62e+02, 1.03e+01, 1.27e+02, 2.36e+00]    [4.62e+02, 1.03e+01, 1.27e+02, 2.36e+00]    []
1000      [1.54e+01, 3.95e-01, 2.02e+00, 7.48e-02]    [1.54e+01, 3.95e-01, 2.02e+00, 7.48e-02]    []
2000      [1.59e+00, 1.54e-01, 2.49e-01, 2.30e-02]    [1.59e+00, 1.54e-01, 2.49e-01, 2.30e-02]    []
3000      [6.37e-01, 8.74e-03, 2.39e-01, 1.54e-02]    [6.37e-01, 8.74e-03, 2.39e-01, 1.54e-02]    []
4000      [3.80e-01, 6.81e-03, 2.08e-01, 6.47e-03]    [3.80e-01, 6.81e-03, 2.08e-01, 6.47e-03]    []
5000      [5.10e-01, 2.93e-03, 1.39e-01, 1.75e-03]    [5.10e-01, 2.93e-03, 1.39e-01, 1.75e-03]    []
6000      [3.21e-01, 1.44e-03, 2.54e-02, 3.01e-03]    [3.21e-01, 1.44e-03, 2.54e-02, 3.01e-03]    []
7000      [1.24e-01, 1.50e-03, 3.29e-02, 3.07e-03]    [1.24e-01, 1.50e-03, 3.29e-02, 3.07e-03]    []
8000      [1.79e-01, 6.50e-03, 1.78e-02, 1.01e-02]    [1.79e-01, 6.50e-03, 1.78e-02, 1.01e-02]    []
9000      [1.31e-01, 1.38e-03, 1.67e-02, 1.67e-03]    [1.31e-01, 1.38e-03, 1.67e-02, 1.67e-03]    []
10000     [2.99e-01, 1.14e-02, 5.31e-02, 3.39e-03]    [2.99e-01, 1.14e-02, 5.31e-02, 3.39e-03]    []
11000     [9.96e-02, 2.98e-03, 1.83e-02, 2.85e-03]    [9.96e-02, 2.98e-03, 1.83e-02, 2.85e-03]    []
12000     [7.30e-02, 1.04e-03, 8.27e-03, 1.97e-03]    [7.30e-02, 1.04e-03, 8.27e-03, 1.97e-03]    []
13000     [8.68e-02, 8.42e-04, 1.35e-02, 1.91e-03]    [8.68e-02, 8.42e-04, 1.35e-02, 1.91e-03]    []
14000     [1.31e-01, 1.79e-03, 3.54e-03, 1.37e-03]    [1.31e-01, 1.79e-03, 3.54e-03, 1.37e-03]    []
15000     [1.62e-01, 1.85e-03, 1.75e-02, 3.58e-03]    [1.62e-01, 1.85e-03, 1.75e-02, 3.58e-03]    []
16000     [9.97e-02, 7.94e-04, 2.24e-02, 7.44e-04]    [9.97e-02, 7.94e-04, 2.24e-02, 7.44e-04]    []
17000     [1.81e-01, 1.45e-02, 1.47e-01, 6.32e-03]    [1.81e-01, 1.45e-02, 1.47e-01, 6.32e-03]    []
18000     [1.81e-01, 4.64e-03, 1.77e-02, 4.08e-03]    [1.81e-01, 4.64e-03, 1.77e-02, 4.08e-03]    []
19000     [9.85e-02, 1.51e-03, 2.78e-02, 1.48e-03]    [9.85e-02, 1.51e-03, 2.78e-02, 1.48e-03]    []
20000     [9.83e-02, 3.61e-03, 2.90e-02, 3.03e-03]    [9.83e-02, 3.61e-03, 2.90e-02, 3.03e-03]    []
Best model at step 12000:
  train loss: 8.43e-02
  test loss: 8.43e-02
  test metric: []
Epoch 20000: saving model to /home/giuglielmocappellini/Projects/PINNs/23.07.09_source_m_obs/hpo/129_483/model/3.ckpt-20000.pt ...
'train' took 51.585161 s
Saving loss history to /home/giuglielmocappellini/Projects/PINNs/23.07.09_source_m_obs/hpo/129_483/history/3_loss ...
Saving training data to /home/giuglielmocappellini/Projects/PINNs/23.07.09_source_m_obs/hpo/129_483/history/3_train ...
Saving test data to /home/giuglielmocappellini/Projects/PINNs/23.07.09_source_m_obs/hpo/129_483/history/3_test ...